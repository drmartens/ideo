{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import keras models instead of sequential\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the Input\n",
    "our_input = Input(shape=(6,16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply a convolutional layer using the functional API\n",
    "x = Conv2D(64, (3,3))(our_input)\n",
    "x = Conv2D(64,(3,3))(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "out = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a Model\n",
    "vision_model = Model(our_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "dataset = numpy.loadtxt(\"trialSocks.csv\", delimiter=\",\")\n",
    "#Split data set into input (X) and output (Y) variables\n",
    "X = dataset[:,0:LAYERS[0]]\n",
    "Y = dataset[:,LAYERS[0]: LAYERS[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFINE THE MODEL - SEQUENCE OF LAYERS\n",
    "#Create a sequential model and add layer one at a time\n",
    "#Until we are happy with network topology\n",
    "\n",
    "#Layers\n",
    "LAYERS = [6, 16, 1]\n",
    "\n",
    "#Create a Model\n",
    "model = Sequential()\n",
    "model.add(Dense(LAYERS[0],input_dim=LAYERS[0], activation='relu'))\n",
    "model.add(Dense(LAYERS[1], activation='relu'))\n",
    "model.add(Dense(LAYERS[2], activation = 'sigmoid'))\n",
    "\n",
    "#Compile the Model\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the Model\n",
    "#we can train or fit the model on loaded data by calling the fit() function on the model\n",
    "#Training process runs for fixed # iterations throu ght data called\n",
    "#epochs. We need to specify this  in nepochs\n",
    "\n",
    "model.fit(X,Y, epochs=100,batch_size=10)\n",
    "\n",
    "#EVALUATE THE MODEL\n",
    "#now that we have trained it on training data, evaluate performance on same dataset\n",
    "#Lets us know how well we modeled the dataset, but not\n",
    "#How it will perform on new data\n",
    "\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TIE IT ALL TOGETHER - PREDICT SOMETHING!!!!\n",
    "\n",
    "predictions=model.predict(X)\n",
    "print (predictions)\n",
    "\n",
    "#round the predictions\n",
    "rounded = [round(x[0], 1) for x in predictions]\n",
    "print (rounded)\n",
    "\n",
    "big = max(rounded)\n",
    "spot = rounded.index(big)\n",
    "\n",
    "print(\"spot is\", spot)\n",
    "print(\"big is\", big)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
